{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWAG MCQ Reasoning with BERT and In-Context Learning\n",
    "\n",
    "This notebook implements **Task 3** from the *Introduction to Data Science - Assignment 5&6*. The goal is to explore how **Large Language Models (LLMs)**, specifically BERT, can solve **multiple-choice commonsense reasoning questions** from the **SWAG dataset**.\n",
    "\n",
    "Traditional machine learning models struggle with nuanced semantic inference tasks. Here, we utilize modern LLM techniques‚Äîincluding **zero-shot prediction**, **in-context learning (ICL)**, and **fine-tuning with LoRA**‚Äîto handle the task effectively.\n",
    "\n",
    "### üîç Task Overview\n",
    "We work with the **SWAG dataset** (113k+ MCQs) to:\n",
    "- Preprocess and tokenize inputs in multiple-choice format.\n",
    "- Evaluate BERT in a zero-shot setting.\n",
    "- Apply in-context learning using prompt engineering.\n",
    "- Fine-tune the BERT model with LoRA for performance gains.\n",
    "- Compare model performance across zero-shot, ICL, and fine-tuned configurations.\n",
    "\n",
    "### üß† Learning Objective\n",
    "- Understand the limitations of classical models for reasoning tasks.\n",
    "- Apply prompt-based and fine-tuning strategies for LLMs.\n",
    "- Use HuggingFace Transformers to load, preprocess, evaluate, and fine-tune models.\n",
    "- Analyze results using accuracy, confusion matrix, and perplexity.\n",
    "\n",
    "**Dataset:** [SWAG - Situations With Adversarial Generations](https://huggingface.co/datasets/allenai/swag)\n",
    "            \n",
    "### üìå Note\n",
    "Make sure to\n",
    "- Use your Hugging Face token for access.\n",
    "- Run on Kaggle for reliable GPU access and smoother performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:47:40.804384Z",
     "iopub.status.busy": "2025-08-24T10:47:40.804105Z",
     "iopub.status.idle": "2025-08-24T10:47:40.809254Z",
     "shell.execute_reply": "2025-08-24T10:47:40.808549Z",
     "shell.execute_reply.started": "2025-08-24T10:47:40.804358Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # 1) Uninstall any leftovers\n",
    "# !pip uninstall -y transformers tokenizers\n",
    "\n",
    "# # 2) Install the last version before the helpers were removed\n",
    "# !pip install --no-cache-dir transformers==4.27.4\n",
    "\n",
    "# # 3) Now install your other libraries (they won‚Äôt bump Transformers because 4.27.4 satisfies PEFT)\n",
    "# !pip install --no-cache-dir peft evaluate packaging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:47:40.810293Z",
     "iopub.status.busy": "2025-08-24T10:47:40.809977Z",
     "iopub.status.idle": "2025-08-24T10:47:40.827599Z",
     "shell.execute_reply": "2025-08-24T10:47:40.826886Z",
     "shell.execute_reply.started": "2025-08-24T10:47:40.810268Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip uninstall -y transformers tokenizers datasets fsspec peft evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:47:40.828532Z",
     "iopub.status.busy": "2025-08-24T10:47:40.828326Z",
     "iopub.status.idle": "2025-08-24T10:47:49.809509Z",
     "shell.execute_reply": "2025-08-24T10:47:49.808854Z",
     "shell.execute_reply.started": "2025-08-24T10:47:40.828516Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-24 10:47:46.965133: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756032466.988753     180 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756032466.995820     180 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers: 4.52.4\n",
      "Datasets: 3.6.0\n",
      "Fsspec: 2025.3.0\n",
      "PEFT: 0.15.2\n"
     ]
    }
   ],
   "source": [
    "import transformers, datasets, fsspec, peft\n",
    "print(\"Transformers:\", transformers.__version__)\n",
    "print(\"Datasets:\", datasets.__version__)\n",
    "print(\"Fsspec:\", fsspec.__version__)\n",
    "print(\"PEFT:\", peft.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:47:49.810718Z",
     "iopub.status.busy": "2025-08-24T10:47:49.810239Z",
     "iopub.status.idle": "2025-08-24T10:47:49.813920Z",
     "shell.execute_reply": "2025-08-24T10:47:49.813097Z",
     "shell.execute_reply.started": "2025-08-24T10:47:49.810688Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip uninstall -y transformers\n",
    "# !pip install transformers==4.27.4 --no-cache-dir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:47:49.816109Z",
     "iopub.status.busy": "2025-08-24T10:47:49.815907Z",
     "iopub.status.idle": "2025-08-24T10:47:49.828464Z",
     "shell.execute_reply": "2025-08-24T10:47:49.827894Z",
     "shell.execute_reply.started": "2025-08-24T10:47:49.816092Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import transformers\n",
    "# print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:47:49.829462Z",
     "iopub.status.busy": "2025-08-24T10:47:49.829224Z",
     "iopub.status.idle": "2025-08-24T10:47:49.841491Z",
     "shell.execute_reply": "2025-08-24T10:47:49.840926Z",
     "shell.execute_reply.started": "2025-08-24T10:47:49.829445Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hugging Face Access Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:47:49.842426Z",
     "iopub.status.busy": "2025-08-24T10:47:49.842175Z",
     "iopub.status.idle": "2025-08-24T10:47:49.976150Z",
     "shell.execute_reply": "2025-08-24T10:47:49.975409Z",
     "shell.execute_reply.started": "2025-08-24T10:47:49.842404Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Hugging Face Login\n",
    "from huggingface_hub import notebook_login, login\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:47:49.977220Z",
     "iopub.status.busy": "2025-08-24T10:47:49.976950Z",
     "iopub.status.idle": "2025-08-24T10:47:54.028437Z",
     "shell.execute_reply": "2025-08-24T10:47:54.027867Z",
     "shell.execute_reply.started": "2025-08-24T10:47:49.977195Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['video-id', 'fold-ind', 'startphrase', 'sent1', 'sent2', 'gold-source', 'ending0', 'ending1', 'ending2', 'ending3', 'label'],\n",
      "        num_rows: 73546\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['video-id', 'fold-ind', 'startphrase', 'sent1', 'sent2', 'gold-source', 'ending0', 'ending1', 'ending2', 'ending3', 'label'],\n",
      "        num_rows: 20006\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['video-id', 'fold-ind', 'startphrase', 'sent1', 'sent2', 'gold-source', 'ending0', 'ending1', 'ending2', 'ending3', 'label'],\n",
      "        num_rows: 20005\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'video-id': 'anetv_jkn6uvmqwh4',\n",
       " 'fold-ind': '3416',\n",
       " 'startphrase': 'Members of the procession walk down the street holding small horn brass instruments. A drum line',\n",
       " 'sent1': 'Members of the procession walk down the street holding small horn brass instruments.',\n",
       " 'sent2': 'A drum line',\n",
       " 'gold-source': 'gold',\n",
       " 'ending0': 'passes by walking down the street playing their instruments.',\n",
       " 'ending1': 'has heard approaching them.',\n",
       " 'ending2': \"arrives and they're outside dancing and asleep.\",\n",
       " 'ending3': 'turns the lead singer watches the performance.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the SWAG dataset\n",
    "dataset = load_dataset(\"swag\", \"regular\")\n",
    "\n",
    "df_train = dataset['train'].to_pandas()\n",
    "df_val = dataset['validation'].to_pandas()\n",
    "df_test = dataset['test'].to_pandas()\n",
    "\n",
    "# adding a column to specify the split\n",
    "df_train['split'] = 'train'\n",
    "df_val['split'] = 'validation'\n",
    "df_test['split'] = 'test'\n",
    "# Concatenate all into one DataFrame\n",
    "df = pd.concat([df_train, df_val, df_test], ignore_index=True)\n",
    "\n",
    "print(dataset)\n",
    "dataset[\"train\"][0]\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyza the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:47:54.029694Z",
     "iopub.status.busy": "2025-08-24T10:47:54.029430Z",
     "iopub.status.idle": "2025-08-24T10:47:54.042011Z",
     "shell.execute_reply": "2025-08-24T10:47:54.041419Z",
     "shell.execute_reply.started": "2025-08-24T10:47:54.029668Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video-id</th>\n",
       "      <th>fold-ind</th>\n",
       "      <th>startphrase</th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>gold-source</th>\n",
       "      <th>ending0</th>\n",
       "      <th>ending1</th>\n",
       "      <th>ending2</th>\n",
       "      <th>ending3</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anetv_jkn6uvmqwh4</td>\n",
       "      <td>3416</td>\n",
       "      <td>Members of the procession walk down the street...</td>\n",
       "      <td>Members of the procession walk down the street...</td>\n",
       "      <td>A drum line</td>\n",
       "      <td>gold</td>\n",
       "      <td>passes by walking down the street playing thei...</td>\n",
       "      <td>has heard approaching them.</td>\n",
       "      <td>arrives and they're outside dancing and asleep.</td>\n",
       "      <td>turns the lead singer watches the performance.</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anetv_jkn6uvmqwh4</td>\n",
       "      <td>3417</td>\n",
       "      <td>A drum line passes by walking down the street ...</td>\n",
       "      <td>A drum line passes by walking down the street ...</td>\n",
       "      <td>Members of the procession</td>\n",
       "      <td>gen</td>\n",
       "      <td>are playing ping pong and celebrating one left...</td>\n",
       "      <td>wait slowly towards the cadets.</td>\n",
       "      <td>continues to play as well along the crowd alon...</td>\n",
       "      <td>continue to play marching, interspersed.</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anetv_jkn6uvmqwh4</td>\n",
       "      <td>3415</td>\n",
       "      <td>A group of members in green uniforms walks wav...</td>\n",
       "      <td>A group of members in green uniforms walks wav...</td>\n",
       "      <td>Members of the procession</td>\n",
       "      <td>gold</td>\n",
       "      <td>pay the other coaches to cheer as people this ...</td>\n",
       "      <td>walk down the street holding small horn brass ...</td>\n",
       "      <td>is seen in the background.</td>\n",
       "      <td>are talking a couple of people playing a game ...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anetv_jkn6uvmqwh4</td>\n",
       "      <td>3417</td>\n",
       "      <td>A drum line passes by walking down the street ...</td>\n",
       "      <td>A drum line passes by walking down the street ...</td>\n",
       "      <td>Members of the procession</td>\n",
       "      <td>gen</td>\n",
       "      <td>are playing ping pong and celebrating one left...</td>\n",
       "      <td>wait slowly towards the cadets.</td>\n",
       "      <td>makes a square call and ends by jumping down i...</td>\n",
       "      <td>play and go back and forth hitting the drums w...</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            video-id fold-ind  \\\n",
       "0  anetv_jkn6uvmqwh4     3416   \n",
       "1  anetv_jkn6uvmqwh4     3417   \n",
       "2  anetv_jkn6uvmqwh4     3415   \n",
       "3  anetv_jkn6uvmqwh4     3417   \n",
       "\n",
       "                                         startphrase  \\\n",
       "0  Members of the procession walk down the street...   \n",
       "1  A drum line passes by walking down the street ...   \n",
       "2  A group of members in green uniforms walks wav...   \n",
       "3  A drum line passes by walking down the street ...   \n",
       "\n",
       "                                               sent1  \\\n",
       "0  Members of the procession walk down the street...   \n",
       "1  A drum line passes by walking down the street ...   \n",
       "2  A group of members in green uniforms walks wav...   \n",
       "3  A drum line passes by walking down the street ...   \n",
       "\n",
       "                       sent2 gold-source  \\\n",
       "0                A drum line        gold   \n",
       "1  Members of the procession         gen   \n",
       "2  Members of the procession        gold   \n",
       "3  Members of the procession         gen   \n",
       "\n",
       "                                             ending0  \\\n",
       "0  passes by walking down the street playing thei...   \n",
       "1  are playing ping pong and celebrating one left...   \n",
       "2  pay the other coaches to cheer as people this ...   \n",
       "3  are playing ping pong and celebrating one left...   \n",
       "\n",
       "                                             ending1  \\\n",
       "0                        has heard approaching them.   \n",
       "1                    wait slowly towards the cadets.   \n",
       "2  walk down the street holding small horn brass ...   \n",
       "3                    wait slowly towards the cadets.   \n",
       "\n",
       "                                             ending2  \\\n",
       "0    arrives and they're outside dancing and asleep.   \n",
       "1  continues to play as well along the crowd alon...   \n",
       "2                         is seen in the background.   \n",
       "3  makes a square call and ends by jumping down i...   \n",
       "\n",
       "                                             ending3  label  split  \n",
       "0     turns the lead singer watches the performance.      0  train  \n",
       "1           continue to play marching, interspersed.      3  train  \n",
       "2  are talking a couple of people playing a game ...      1  train  \n",
       "3  play and go back and forth hitting the drums w...      3  train  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:47:54.043214Z",
     "iopub.status.busy": "2025-08-24T10:47:54.042796Z",
     "iopub.status.idle": "2025-08-24T10:47:54.119374Z",
     "shell.execute_reply": "2025-08-24T10:47:54.118600Z",
     "shell.execute_reply.started": "2025-08-24T10:47:54.043190Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 113557 entries, 0 to 113556\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   video-id     113557 non-null  object\n",
      " 1   fold-ind     113557 non-null  object\n",
      " 2   startphrase  113557 non-null  object\n",
      " 3   sent1        113557 non-null  object\n",
      " 4   sent2        113557 non-null  object\n",
      " 5   gold-source  113557 non-null  object\n",
      " 6   ending0      113557 non-null  object\n",
      " 7   ending1      113557 non-null  object\n",
      " 8   ending2      113557 non-null  object\n",
      " 9   ending3      113557 non-null  object\n",
      " 10  label        113557 non-null  int64 \n",
      " 11  split        113557 non-null  object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 10.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:47:54.120384Z",
     "iopub.status.busy": "2025-08-24T10:47:54.120192Z",
     "iopub.status.idle": "2025-08-24T10:47:54.652479Z",
     "shell.execute_reply": "2025-08-24T10:47:54.651875Z",
     "shell.execute_reply.started": "2025-08-24T10:47:54.120369Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video-id</th>\n",
       "      <th>fold-ind</th>\n",
       "      <th>startphrase</th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>gold-source</th>\n",
       "      <th>ending0</th>\n",
       "      <th>ending1</th>\n",
       "      <th>ending2</th>\n",
       "      <th>ending3</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>113557</td>\n",
       "      <td>113557</td>\n",
       "      <td>113557</td>\n",
       "      <td>113557</td>\n",
       "      <td>113557</td>\n",
       "      <td>113557</td>\n",
       "      <td>113557</td>\n",
       "      <td>113557</td>\n",
       "      <td>113557</td>\n",
       "      <td>113557</td>\n",
       "      <td>113557.000000</td>\n",
       "      <td>113557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>21615</td>\n",
       "      <td>20083</td>\n",
       "      <td>92221</td>\n",
       "      <td>91712</td>\n",
       "      <td>26602</td>\n",
       "      <td>2</td>\n",
       "      <td>108368</td>\n",
       "      <td>108270</td>\n",
       "      <td>108234</td>\n",
       "      <td>108490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>lsmdc3047_LIFE_OF_PI-22387</td>\n",
       "      <td>8191</td>\n",
       "      <td>We see an opening title screen. We</td>\n",
       "      <td>We see an opening title screen.</td>\n",
       "      <td>Someone</td>\n",
       "      <td>gold</td>\n",
       "      <td>see the ending title screen.</td>\n",
       "      <td>talks to the camera.</td>\n",
       "      <td>talks to the camera.</td>\n",
       "      <td>talks to the camera.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>211</td>\n",
       "      <td>13</td>\n",
       "      <td>52</td>\n",
       "      <td>94</td>\n",
       "      <td>19005</td>\n",
       "      <td>87939</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.061194</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.392450</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          video-id fold-ind  \\\n",
       "count                       113557   113557   \n",
       "unique                       21615    20083   \n",
       "top     lsmdc3047_LIFE_OF_PI-22387     8191   \n",
       "freq                           211       13   \n",
       "mean                           NaN      NaN   \n",
       "std                            NaN      NaN   \n",
       "min                            NaN      NaN   \n",
       "25%                            NaN      NaN   \n",
       "50%                            NaN      NaN   \n",
       "75%                            NaN      NaN   \n",
       "max                            NaN      NaN   \n",
       "\n",
       "                               startphrase                            sent1  \\\n",
       "count                               113557                           113557   \n",
       "unique                               92221                            91712   \n",
       "top     We see an opening title screen. We  We see an opening title screen.   \n",
       "freq                                    52                               94   \n",
       "mean                                   NaN                              NaN   \n",
       "std                                    NaN                              NaN   \n",
       "min                                    NaN                              NaN   \n",
       "25%                                    NaN                              NaN   \n",
       "50%                                    NaN                              NaN   \n",
       "75%                                    NaN                              NaN   \n",
       "max                                    NaN                              NaN   \n",
       "\n",
       "          sent2 gold-source                       ending0  \\\n",
       "count    113557      113557                        113557   \n",
       "unique    26602           2                        108368   \n",
       "top     Someone        gold  see the ending title screen.   \n",
       "freq      19005       87939                            33   \n",
       "mean        NaN         NaN                           NaN   \n",
       "std         NaN         NaN                           NaN   \n",
       "min         NaN         NaN                           NaN   \n",
       "25%         NaN         NaN                           NaN   \n",
       "50%         NaN         NaN                           NaN   \n",
       "75%         NaN         NaN                           NaN   \n",
       "max         NaN         NaN                           NaN   \n",
       "\n",
       "                     ending1               ending2               ending3  \\\n",
       "count                 113557                113557                113557   \n",
       "unique                108270                108234                108490   \n",
       "top     talks to the camera.  talks to the camera.  talks to the camera.   \n",
       "freq                      35                    31                    31   \n",
       "mean                     NaN                   NaN                   NaN   \n",
       "std                      NaN                   NaN                   NaN   \n",
       "min                      NaN                   NaN                   NaN   \n",
       "25%                      NaN                   NaN                   NaN   \n",
       "50%                      NaN                   NaN                   NaN   \n",
       "75%                      NaN                   NaN                   NaN   \n",
       "max                      NaN                   NaN                   NaN   \n",
       "\n",
       "                label   split  \n",
       "count   113557.000000  113557  \n",
       "unique            NaN       3  \n",
       "top               NaN   train  \n",
       "freq              NaN   73546  \n",
       "mean         1.061194     NaN  \n",
       "std          1.392450     NaN  \n",
       "min         -1.000000     NaN  \n",
       "25%          0.000000     NaN  \n",
       "50%          1.000000     NaN  \n",
       "75%          2.000000     NaN  \n",
       "max          3.000000     NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:47:54.653459Z",
     "iopub.status.busy": "2025-08-24T10:47:54.653193Z",
     "iopub.status.idle": "2025-08-24T10:47:54.831757Z",
     "shell.execute_reply": "2025-08-24T10:47:54.830930Z",
     "shell.execute_reply.started": "2025-08-24T10:47:54.653436Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(x='label', data=df)\n",
    "plt.title(\"Distribution of Correct Answer Labels\")\n",
    "plt.xlabel(\"Correct Ending (0-3)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avg length of sent1, sent2, ending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:47:54.833245Z",
     "iopub.status.busy": "2025-08-24T10:47:54.832659Z",
     "iopub.status.idle": "2025-08-24T10:47:55.313009Z",
     "shell.execute_reply": "2025-08-24T10:47:55.312351Z",
     "shell.execute_reply.started": "2025-08-24T10:47:54.833223Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average lengths:\n",
      "sent1: 11.54 words\n",
      "sent2: 2.70 words\n",
      "ending0: 8.67 words\n",
      "ending1: 8.69 words\n",
      "ending2: 8.66 words\n",
      "ending3: 8.65 words\n",
      "Max lengths:\n",
      "sent1: 74.00 words\n",
      "sent2: 76.00 words\n",
      "ending0: 25.00 words\n",
      "ending1: 25.00 words\n",
      "ending2: 25.00 words\n",
      "ending3: 25.00 words\n"
     ]
    }
   ],
   "source": [
    "df['sent1_len'] = df['sent1'].apply(lambda x: len(x.split()))\n",
    "df['sent2_len'] = df['sent2'].apply(lambda x: len(x.split()))\n",
    "for i in range(4):\n",
    "    df[f'ending{i}_len'] = df[f'ending{i}'].apply(lambda x: len(x.split()))\n",
    "    \n",
    "# Display averages\n",
    "print(\"Average lengths:\")\n",
    "print(f\"sent1: {df['sent1_len'].mean():.2f} words\")\n",
    "print(f\"sent2: {df['sent2_len'].mean():.2f} words\")\n",
    "for i in range(4):\n",
    "    print(f\"ending{i}: {df[f'ending{i}_len'].mean():.2f} words\")\n",
    "    \n",
    "# Display max\n",
    "print(\"Max lengths:\")\n",
    "print(f\"sent1: {df['sent1_len'].max():.2f} words\")\n",
    "print(f\"sent2: {df['sent2_len'].max():.2f} words\")\n",
    "for i in range(4):    \n",
    "    print(f\"ending{i}: {df[f'ending{i}_len'].max():.2f} words\")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One full mcq example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:47:55.314054Z",
     "iopub.status.busy": "2025-08-24T10:47:55.313808Z",
     "iopub.status.idle": "2025-08-24T10:47:55.319373Z",
     "shell.execute_reply": "2025-08-24T10:47:55.318651Z",
     "shell.execute_reply.started": "2025-08-24T10:47:55.314036Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent1: Members of the procession walk down the street holding small horn brass instruments.\n",
      "sent2: A drum line\n",
      "ending0: passes by walking down the street playing their instruments.\n",
      "Correct label: 0\n",
      "ending1: has heard approaching them.\n",
      "Correct label: 0\n",
      "ending2: arrives and they're outside dancing and asleep.\n",
      "Correct label: 0\n",
      "ending3: turns the lead singer watches the performance.\n",
      "Correct label: 0\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(\"sent1:\", df.loc[i, 'sent1'])\n",
    "print(\"sent2:\", df.loc[i, 'sent2'])\n",
    "for j in range(4):\n",
    "    print(f\"ending{j}:\", df.loc[i, f'ending{j}'])\n",
    "    print(\"Correct label:\", df.loc[i, 'label'])\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:47:55.320378Z",
     "iopub.status.busy": "2025-08-24T10:47:55.320082Z",
     "iopub.status.idle": "2025-08-24T10:47:55.624289Z",
     "shell.execute_reply": "2025-08-24T10:47:55.623469Z",
     "shell.execute_reply.started": "2025-08-24T10:47:55.320361Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "# loading tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pre-Process the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T14:49:42.409530Z",
     "iopub.status.busy": "2025-08-24T14:49:42.408810Z",
     "iopub.status.idle": "2025-08-24T14:49:42.414965Z",
     "shell.execute_reply": "2025-08-24T14:49:42.414071Z",
     "shell.execute_reply.started": "2025-08-24T14:49:42.409504Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_swag(batch):\n",
    "    first_sentences = [s1 for s1 in batch['sent1'] for _ in range(4)]\n",
    "    second_sentences = [\n",
    "        batch['sent2'][i] + \" \" + batch[f'ending{j}'][i]\n",
    "        for i in range(len(batch['sent1']))\n",
    "        for j in range(4)\n",
    "    ]\n",
    "    \n",
    "    tokenized = tokenizer(\n",
    "        first_sentences,\n",
    "        second_sentences,\n",
    "        truncation=True,\n",
    "        padding=\"longest\"\n",
    "        )\n",
    "    # Unflatten: group every 4 items as a list\n",
    "    def regroup(values):\n",
    "        return [values[i:i + 4] for i in range(0, len(values), 4)]\n",
    "    \n",
    "    return {key: regroup(val) for key, val in tokenized.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Apply the preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T14:49:46.964423Z",
     "iopub.status.busy": "2025-08-24T14:49:46.964173Z",
     "iopub.status.idle": "2025-08-24T14:50:39.806026Z",
     "shell.execute_reply": "2025-08-24T14:50:39.805246Z",
     "shell.execute_reply.started": "2025-08-24T14:49:46.964407Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30eb7fb8f00444cebc0203a1c56262ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/73546 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5090f8578c484cdc97723110a0c25048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20006 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8745a465f867445ebf9562fbb624c177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply preprocessing function with batch\n",
    "tokenized_dataset = {\n",
    "    split: dataset[split].map(preprocess_swag, batched=True)\n",
    "    for split in [\"train\", \"validation\", \"test\"]\n",
    "}\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T14:53:03.304252Z",
     "iopub.status.busy": "2025-08-24T14:53:03.303533Z",
     "iopub.status.idle": "2025-08-24T14:53:03.308332Z",
     "shell.execute_reply": "2025-08-24T14:53:03.307649Z",
     "shell.execute_reply.started": "2025-08-24T14:53:03.304229Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# clean and finalize the dataset\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    if \"label\" in tokenized_dataset[split].column_names:\n",
    "        tokenized_dataset[split] = tokenized_dataset[split].rename_column(\"label\", \"labels\")\n",
    "        \n",
    "        keep_cols = ['input_ids', 'attention_mask', 'token_type_ids', 'labels']\n",
    "        tokenized_dataset[split] = tokenized_dataset[split].remove_columns(\n",
    "            [col for col in tokenized_dataset[split].column_names if col not in keep_cols]\n",
    "        )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:48:05.383640Z",
     "iopub.status.busy": "2025-08-24T10:48:05.383446Z",
     "iopub.status.idle": "2025-08-24T10:48:05.538515Z",
     "shell.execute_reply": "2025-08-24T10:48:05.537749Z",
     "shell.execute_reply.started": "2025-08-24T10:48:05.383624Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers.data.data_collator import DataCollatorForMultipleChoice\n",
    "\n",
    "data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:48:05.539468Z",
     "iopub.status.busy": "2025-08-24T10:48:05.539262Z",
     "iopub.status.idle": "2025-08-24T10:48:05.818330Z",
     "shell.execute_reply": "2025-08-24T10:48:05.817745Z",
     "shell.execute_reply.started": "2025-08-24T10:48:05.539451Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMultipleChoice\n",
    "\n",
    "model = AutoModelForMultipleChoice.from_pretrained(\"google-bert/bert-base-uncased\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test Model on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:48:05.819316Z",
     "iopub.status.busy": "2025-08-24T10:48:05.819067Z",
     "iopub.status.idle": "2025-08-24T10:48:06.110213Z",
     "shell.execute_reply": "2025-08-24T10:48:06.109617Z",
     "shell.execute_reply.started": "2025-08-24T10:48:05.819299Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# This will store (method, accuracy)\n",
    "icl_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test case analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:48:06.111200Z",
     "iopub.status.busy": "2025-08-24T10:48:06.110959Z",
     "iopub.status.idle": "2025-08-24T10:48:06.316627Z",
     "shell.execute_reply": "2025-08-24T10:48:06.315931Z",
     "shell.execute_reply.started": "2025-08-24T10:48:06.111181Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Context: Students lower their eyes nervously. She\n",
      "üîò Options:\n",
      "   ‚ùå Choice 0: pats her shoulder, then saunters toward someone.\n",
      "   ‚ùå Choice 1: turns with two students.\n",
      "   ‚úÖ Choice 2: walks slowly towards someone.\n",
      "üëâ ‚ùå Choice 3: wheels around as her dog thunders out.\n",
      "üß† Model Prediction: Choice 3\n",
      "‚úîÔ∏è Ground Truth: Choice 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Device setup (should match your model)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Pick a single example to inspect\n",
    "i = 0  # You can change this index to test other samples\n",
    "example = tokenized_dataset[\"validation\"][i]\n",
    "raw_example = dataset[\"validation\"][i]  # un-tokenized version for readable display\n",
    "\n",
    "# Convert inputs to tensor format (batch size = 1) and move to device\n",
    "input = {\n",
    "    k: torch.tensor([example[k]]).to(device)\n",
    "    for k in [\"input_ids\", \"attention_mask\", \"token_type_ids\"]\n",
    "}\n",
    "\n",
    "# Run the model and get prediction\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**input)\n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "# Display the context\n",
    "context = raw_example[\"sent1\"] + \" \" + raw_example[\"sent2\"]\n",
    "print(f\"üìå Context: {context}\")\n",
    "\n",
    "# Display all choices with prediction and ground truth\n",
    "print(\"üîò Options:\")\n",
    "for j in range(4):\n",
    "    option_text = raw_example[f\"ending{j}\"]\n",
    "    prefix = \"‚úÖ\" if j == raw_example[\"label\"] else \"‚ùå\"\n",
    "    marker = \"üëâ\" if j == predicted_class else \"  \"\n",
    "    print(f\"{marker} {prefix} Choice {j}: {option_text}\")\n",
    "\n",
    "# Final Summary\n",
    "print(f\"üß† Model Prediction: Choice {predicted_class}\")\n",
    "print(f\"‚úîÔ∏è Ground Truth: Choice {raw_example['label']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full valildation set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:48:06.317541Z",
     "iopub.status.busy": "2025-08-24T10:48:06.317332Z",
     "iopub.status.idle": "2025-08-24T10:51:51.367008Z",
     "shell.execute_reply": "2025-08-24T10:51:51.366048Z",
     "shell.execute_reply.started": "2025-08-24T10:48:06.317524Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Baseline:   0%|          | 0/1251 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Evaluating Baseline: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1251/1251 [03:45<00:00,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Baseline Accuracy: 39.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_loader = DataLoader(\n",
    "    tokenized_dataset[\"validation\"],\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator)\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for batch in tqdm(val_loader, desc=\"Evaluating Baseline\"):\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "        predictions = torch.argmax(outputs.logits, dim=1)\n",
    "        correct += (predictions == batch[\"labels\"]).sum().item()\n",
    "        total += batch[\"labels\"].size(0)\n",
    "        \n",
    "baseline_acc = 100*(correct / total)\n",
    "print(f\"üìä Baseline Accuracy: {baseline_acc:.2f}%\")\n",
    "icl_results.append((\"Baseline (No ICL)\", baseline_acc))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. In-Context Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:51:51.368527Z",
     "iopub.status.busy": "2025-08-24T10:51:51.367993Z",
     "iopub.status.idle": "2025-08-24T10:51:51.374608Z",
     "shell.execute_reply": "2025-08-24T10:51:51.373876Z",
     "shell.execute_reply.started": "2025-08-24T10:51:51.368499Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMultipleChoice\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorForMultipleChoice\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Select 5-shot ICL examples from validation set\n",
    "fewshot_indices = [0, 1, 2, 3, 4]\n",
    "fewshot_examples = [dataset[\"validation\"][i] for i in fewshot_indices]\n",
    "\n",
    "# Build the static few-shot prompt\n",
    "fewshot_prompt = \"\"\n",
    "for ex in fewshot_examples:\n",
    "    fewshot_prompt += f\"Context: {ex['sent1']} {ex['sent2']}\\n\"\n",
    "    for j in range(4):\n",
    "        fewshot_prompt += f\"{chr(65+j)}. {ex[f'ending{j}']}\\n\"\n",
    "    fewshot_prompt += f\"Answer: {chr(65 + ex['label'])}\\n\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:51:51.375665Z",
     "iopub.status.busy": "2025-08-24T10:51:51.375454Z",
     "iopub.status.idle": "2025-08-24T10:51:51.394173Z",
     "shell.execute_reply": "2025-08-24T10:51:51.393463Z",
     "shell.execute_reply.started": "2025-08-24T10:51:51.375649Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the ICL preprocessing function\n",
    "def preprocess_fewshot_icl_batch(batch):\n",
    "    prompts = []\n",
    "    first_sentences = []\n",
    "    second_sentences = []\n",
    "\n",
    "    for i in range(len(batch['sent1'])):\n",
    "        prompt = fewshot_prompt + f\"\\nContext: {batch['sent1'][i]} {batch['sent2'][i]}\"\n",
    "        first_sentences.extend([prompt] * 4)\n",
    "        second_sentences.extend([\n",
    "            f\"{chr(65 + j)}. {batch[f'ending{j}'][i]}\" for j in range(4)\n",
    "        ])\n",
    "\n",
    "    # print(first_sentences)\n",
    "    # print(second_sentences)\n",
    "    tokenized = tokenizer(first_sentences, second_sentences, truncation=True, padding=\"longest\")\n",
    "\n",
    "    def regroup(values): return [values[i:i+4] for i in range(0, len(values), 4)]\n",
    "    result = {k: regroup(v) for k, v in tokenized.items()}\n",
    "    result[\"labels\"] = batch[\"label\"]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:51:51.394982Z",
     "iopub.status.busy": "2025-08-24T10:51:51.394777Z",
     "iopub.status.idle": "2025-08-24T10:51:51.420717Z",
     "shell.execute_reply": "2025-08-24T10:51:51.420122Z",
     "shell.execute_reply.started": "2025-08-24T10:51:51.394967Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fewshot_icl_dataset = dataset[\"validation\"].map(preprocess_fewshot_icl_batch, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:51:51.421669Z",
     "iopub.status.busy": "2025-08-24T10:51:51.421488Z",
     "iopub.status.idle": "2025-08-24T10:51:51.436179Z",
     "shell.execute_reply": "2025-08-24T10:51:51.435435Z",
     "shell.execute_reply.started": "2025-08-24T10:51:51.421654Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1) Clean & finalize the few-shot ICL dataset\n",
    "\n",
    "# If the old 'label' column still exists, drop it\\nif \"label\" in fewshot_icl_dataset.column_names:\n",
    "fewshot_icl_dataset = fewshot_icl_dataset.remove_columns([\"label\"])\n",
    "\n",
    "# Now keep only the required MCQ fields plus 'labels'\n",
    "keep_cols = [\"input_ids\", \"attention_mask\", \"token_type_ids\", \"labels\"]\n",
    "fewshot_icl_dataset = fewshot_icl_dataset.remove_columns(\n",
    "    [c for c in fewshot_icl_dataset.column_names if c not in keep_cols]\n",
    ")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:51:51.437372Z",
     "iopub.status.busy": "2025-08-24T10:51:51.437092Z",
     "iopub.status.idle": "2025-08-24T11:11:56.511859Z",
     "shell.execute_reply": "2025-08-24T11:11:56.511172Z",
     "shell.execute_reply.started": "2025-08-24T10:51:51.437351Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Few-Shot ICL: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2501/2501 [20:05<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Few-Shot ICL Accuracy: 37.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 2) Create DataLoader with your MCQ collator\n",
    "fewshot_icl_loader = DataLoader(\n",
    "    fewshot_icl_dataset,\n",
    "    batch_size=8,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "# 3) Evaluate Few-Shot ICL\n",
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(fewshot_icl_loader, desc=\"Evaluating Few-Shot ICL\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        correct += (preds == batch[\"labels\"]).sum().item()\n",
    "        total += batch[\"labels\"].size(0)\n",
    "    \n",
    "few_shot_accuracy = 100*(correct / total)\n",
    "print(f\"üìä Few-Shot ICL Accuracy: {few_shot_accuracy:.2f}%\")\n",
    "icl_results.append((\"Few shot learning (ICL)\", few_shot_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-shot with chain of thought (COT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T11:11:56.512884Z",
     "iopub.status.busy": "2025-08-24T11:11:56.512668Z",
     "iopub.status.idle": "2025-08-24T11:11:56.516477Z",
     "shell.execute_reply": "2025-08-24T11:11:56.515813Z",
     "shell.execute_reply.started": "2025-08-24T11:11:56.512867Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1) Build the CoT prompt prefix\n",
    "cot_prefix = \"Let's think step by step.\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T11:11:56.517476Z",
     "iopub.status.busy": "2025-08-24T11:11:56.517251Z",
     "iopub.status.idle": "2025-08-24T11:11:56.531976Z",
     "shell.execute_reply": "2025-08-24T11:11:56.531351Z",
     "shell.execute_reply.started": "2025-08-24T11:11:56.517459Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 2) Define the CoT preprocessing fn\n",
    "def preprocess_cot_batch(batch):\n",
    "    first_sentences = []\n",
    "    second_sentences = []\n",
    "\n",
    "    for i in range(len(batch[\"sent1\"])):\n",
    "        # prepend the chain-of-thought instruction before each example\n",
    "        prompt = cot_prefix + f\"Context: {batch['sent1'][i]} {batch['sent2'][i]}\"\n",
    "        # repeat for the 4 choices\n",
    "        first_sentences.extend([prompt] * 4)\n",
    "        second_sentences.extend([\n",
    "            f\"{chr(65 + j)}. {batch[f'ending{j}'][i]}\" for j in range(4)\n",
    "        ])\n",
    "\n",
    "    # tokenize exactly as before\n",
    "    tokenized = tokenizer(first_sentences, second_sentences,\n",
    "                          truncation=True, padding=\"longest\")\n",
    "\n",
    "    # regroup back into (batch_size, 4, seq_len)\n",
    "    def regroup(vals): return [vals[i : i + 4] for i in range(0, len(vals), 4)]\n",
    "    result = {k: regroup(v) for k, v in tokenized.items()}\n",
    "    # carry label forward\n",
    "    result[\"labels\"] = batch[\"label\"]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T11:11:56.532835Z",
     "iopub.status.busy": "2025-08-24T11:11:56.532660Z",
     "iopub.status.idle": "2025-08-24T11:11:56.560607Z",
     "shell.execute_reply": "2025-08-24T11:11:56.559774Z",
     "shell.execute_reply.started": "2025-08-24T11:11:56.532822Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 3) Map over validation set\n",
    "cot_dataset = dataset[\"validation\"].map(\n",
    "    preprocess_cot_batch,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"validation\"].column_names  # drop raw cols\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T11:11:56.561489Z",
     "iopub.status.busy": "2025-08-24T11:11:56.561295Z",
     "iopub.status.idle": "2025-08-24T11:11:56.571687Z",
     "shell.execute_reply": "2025-08-24T11:11:56.571158Z",
     "shell.execute_reply.started": "2025-08-24T11:11:56.561473Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 4) Clean up columns (drop old 'label' if still there)\n",
    "if \"label\" in cot_dataset.column_names:\n",
    "    cot_dataset = cot_dataset.remove_columns([\"label\"])\n",
    "keep = [\"input_ids\", \"attention_mask\", \"token_type_ids\", \"labels\"]\n",
    "cot_dataset = cot_dataset.remove_columns(\n",
    "    [c for c in cot_dataset.column_names if c not in keep]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T11:11:56.572618Z",
     "iopub.status.busy": "2025-08-24T11:11:56.572421Z",
     "iopub.status.idle": "2025-08-24T11:16:13.841184Z",
     "shell.execute_reply": "2025-08-24T11:16:13.840509Z",
     "shell.execute_reply.started": "2025-08-24T11:11:56.572602Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Zero-Shot CoT: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2501/2501 [04:17<00:00,  9.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Zero-Shot CoT Accuracy: 40.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 5) Create a DataLoader\n",
    "cot_loader = DataLoader(\n",
    "    cot_dataset,\n",
    "    batch_size=8,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "# 6) Evaluate Zero-Shot CoT\n",
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(cot_loader, desc=\"Evaluating Zero-Shot CoT\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        correct += (preds == batch[\"labels\"]).sum().item()\n",
    "        total += batch[\"labels\"].size(0)\n",
    "\n",
    "cot_accuracy = 100*(correct / total)\n",
    "print(f\"\\nüìä Zero-Shot CoT Accuracy: {cot_accuracy:.2f}%\")\n",
    "icl_results.append((\"Chain of Thought (ICL)\", cot_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T11:16:13.842104Z",
     "iopub.status.busy": "2025-08-24T11:16:13.841895Z",
     "iopub.status.idle": "2025-08-24T11:16:13.975649Z",
     "shell.execute_reply": "2025-08-24T11:16:13.974849Z",
     "shell.execute_reply.started": "2025-08-24T11:16:13.842086Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "comparison_df = pd.DataFrame(icl_results, columns=[\"Method\", \"Accuracy\"])\n",
    "comparison_df = comparison_df.sort_values(\"Accuracy\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(data=comparison_df, x=\"Accuracy\", y=\"Method\", palette=\"crest\")\n",
    "plt.title(\"Comparison of ICL Methods on SWAG Validation Set\")\n",
    "plt.xlim(0, 100)\n",
    "plt.xlabel(\"Validation Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Fine-Tune Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T11:16:13.976703Z",
     "iopub.status.busy": "2025-08-24T11:16:13.976488Z",
     "iopub.status.idle": "2025-08-24T11:16:14.476702Z",
     "shell.execute_reply": "2025-08-24T11:16:14.476153Z",
     "shell.execute_reply.started": "2025-08-24T11:16:13.976679Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer, SchedulerType\n",
    "from peft       import LoraConfig, get_peft_model, TaskType\n",
    "import numpy    as np\n",
    "from evaluate   import load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T11:16:14.477653Z",
     "iopub.status.busy": "2025-08-24T11:16:14.477447Z",
     "iopub.status.idle": "2025-08-24T11:16:14.517451Z",
     "shell.execute_reply": "2025-08-24T11:16:14.516876Z",
     "shell.execute_reply.started": "2025-08-24T11:16:14.477636Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_ds = tokenized_dataset[\"train\"]\n",
    "eval_ds  = tokenized_dataset[\"validation\"]\n",
    "\n",
    "base_model = model\n",
    "base_model.to(device)\n",
    "\n",
    "# Config (wrap bert with lora)\n",
    "lora_cfg = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query\", \"value\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    ")\n",
    "model_with_lora = get_peft_model(base_model, lora_cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T11:16:14.518343Z",
     "iopub.status.busy": "2025-08-24T11:16:14.518141Z",
     "iopub.status.idle": "2025-08-24T13:43:14.669478Z",
     "shell.execute_reply": "2025-08-24T13:43:14.668864Z",
     "shell.execute_reply.started": "2025-08-24T11:16:14.518326Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b6541e05784428bfd6ff0e3df42ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "/tmp/ipykernel_180/302647636.py:61: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "***** Running training *****\n",
      "  Num examples = 73,546\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 3,450\n",
      "  Number of trainable parameters = 295,681\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3450' max='3450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3450/3450 2:26:56, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.008200</td>\n",
       "      <td>0.855875</td>\n",
       "      <td>0.660702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.932700</td>\n",
       "      <td>0.776682</td>\n",
       "      <td>0.698640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.896100</td>\n",
       "      <td>0.743415</td>\n",
       "      <td>0.711836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.895900</td>\n",
       "      <td>0.721652</td>\n",
       "      <td>0.718085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.876900</td>\n",
       "      <td>0.708561</td>\n",
       "      <td>0.725132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.855200</td>\n",
       "      <td>0.701657</td>\n",
       "      <td>0.727882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step 50] {'loss': 1.386, 'grad_norm': 1.5575599670410156, 'learning_rate': 5.681159420289856e-06, 'epoch': 0.04350663476180117}\n",
      "[step 100] {'loss': 1.3871, 'grad_norm': 1.056244969367981, 'learning_rate': 1.1478260869565218e-05, 'epoch': 0.08701326952360235}\n",
      "[step 150] {'loss': 1.3743, 'grad_norm': 0.960759162902832, 'learning_rate': 1.727536231884058e-05, 'epoch': 0.13051990428540353}\n",
      "[step 200] {'loss': 1.3534, 'grad_norm': 1.1196753978729248, 'learning_rate': 2.3072463768115943e-05, 'epoch': 0.1740265390472047}\n",
      "[step 250] {'loss': 1.3077, 'grad_norm': 0.9742984175682068, 'learning_rate': 2.8869565217391307e-05, 'epoch': 0.2175331738090059}\n",
      "[step 300] {'loss': 1.1986, 'grad_norm': 2.568655490875244, 'learning_rate': 3.466666666666667e-05, 'epoch': 0.26103980857080705}\n",
      "[step 350] {'loss': 1.1444, 'grad_norm': 1.5619215965270996, 'learning_rate': 3.994847020933978e-05, 'epoch': 0.3045464433326082}\n",
      "[step 400] {'loss': 1.054, 'grad_norm': 2.419137477874756, 'learning_rate': 3.930434782608696e-05, 'epoch': 0.3480530780944094}\n",
      "[step 450] {'loss': 1.0306, 'grad_norm': 1.4679169654846191, 'learning_rate': 3.8660225442834146e-05, 'epoch': 0.39155971285621055}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20006\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step 500] {'loss': 1.0082, 'grad_norm': 2.427065372467041, 'learning_rate': 3.801610305958132e-05, 'epoch': 0.4350663476180118}\n",
      "[step 500] {'eval_loss': 0.8558745980262756, 'eval_accuracy': 0.660701789463161, 'eval_runtime': 235.1985, 'eval_samples_per_second': 85.06, 'eval_steps_per_second': 5.319, 'epoch': 0.4350663476180118}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to swag_lora_ft/checkpoint-500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google-bert--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "tokenizer config file saved in swag_lora_ft/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in swag_lora_ft/checkpoint-500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step 550] {'loss': 1.0103, 'grad_norm': 1.4919174909591675, 'learning_rate': 3.7371980676328506e-05, 'epoch': 0.47857298237981294}\n",
      "[step 600] {'loss': 0.9936, 'grad_norm': 3.1672098636627197, 'learning_rate': 3.6727858293075686e-05, 'epoch': 0.5220796171416141}\n",
      "[step 650] {'loss': 0.9555, 'grad_norm': 1.8804738521575928, 'learning_rate': 3.6083735909822867e-05, 'epoch': 0.5655862519034153}\n",
      "[step 700] {'loss': 0.9417, 'grad_norm': 1.6535313129425049, 'learning_rate': 3.5439613526570054e-05, 'epoch': 0.6090928866652164}\n",
      "[step 750] {'loss': 0.963, 'grad_norm': 1.599323034286499, 'learning_rate': 3.4795491143317234e-05, 'epoch': 0.6525995214270176}\n",
      "[step 800] {'loss': 0.9342, 'grad_norm': 1.7165900468826294, 'learning_rate': 3.4151368760064414e-05, 'epoch': 0.6961061561888188}\n",
      "[step 850] {'loss': 0.9361, 'grad_norm': 2.011836290359497, 'learning_rate': 3.3507246376811594e-05, 'epoch': 0.7396127909506199}\n",
      "[step 900] {'loss': 0.9592, 'grad_norm': 2.05969500541687, 'learning_rate': 3.286312399355878e-05, 'epoch': 0.7831194257124211}\n",
      "[step 950] {'loss': 0.944, 'grad_norm': 1.7735748291015625, 'learning_rate': 3.221900161030596e-05, 'epoch': 0.8266260604742223}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20006\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step 1000] {'loss': 0.9327, 'grad_norm': 1.7610626220703125, 'learning_rate': 3.157487922705314e-05, 'epoch': 0.8701326952360235}\n",
      "[step 1000] {'eval_loss': 0.7766821384429932, 'eval_accuracy': 0.6986404078776367, 'eval_runtime': 235.041, 'eval_samples_per_second': 85.117, 'eval_steps_per_second': 5.322, 'epoch': 0.8701326952360235}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to swag_lora_ft/checkpoint-1000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google-bert--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "tokenizer config file saved in swag_lora_ft/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in swag_lora_ft/checkpoint-1000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step 1050] {'loss': 0.9313, 'grad_norm': 1.7790533304214478, 'learning_rate': 3.093075684380032e-05, 'epoch': 0.9136393299978247}\n",
      "[step 1100] {'loss': 0.9439, 'grad_norm': 2.04967999458313, 'learning_rate': 3.0286634460547506e-05, 'epoch': 0.9571459647596259}\n",
      "[step 1150] {'loss': 0.8858, 'grad_norm': 1.5082412958145142, 'learning_rate': 2.964251207729469e-05, 'epoch': 1.0}\n",
      "[step 1200] {'loss': 0.9148, 'grad_norm': 1.7529948949813843, 'learning_rate': 2.899838969404187e-05, 'epoch': 1.0435066347618012}\n",
      "[step 1250] {'loss': 0.92, 'grad_norm': 2.12750506401062, 'learning_rate': 2.8354267310789053e-05, 'epoch': 1.0870132695236023}\n",
      "[step 1300] {'loss': 0.9027, 'grad_norm': 1.8656983375549316, 'learning_rate': 2.7710144927536237e-05, 'epoch': 1.1305199042854035}\n",
      "[step 1350] {'loss': 0.9137, 'grad_norm': 1.593183994293213, 'learning_rate': 2.7066022544283414e-05, 'epoch': 1.1740265390472047}\n",
      "[step 1400] {'loss': 0.9123, 'grad_norm': 1.9362868070602417, 'learning_rate': 2.6421900161030598e-05, 'epoch': 1.2175331738090058}\n",
      "[step 1450] {'loss': 0.8807, 'grad_norm': 2.127671957015991, 'learning_rate': 2.577777777777778e-05, 'epoch': 1.261039808570807}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20006\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step 1500] {'loss': 0.8961, 'grad_norm': 1.853426218032837, 'learning_rate': 2.513365539452496e-05, 'epoch': 1.3045464433326082}\n",
      "[step 1500] {'eval_loss': 0.7434147000312805, 'eval_accuracy': 0.7118364490652804, 'eval_runtime': 235.2449, 'eval_samples_per_second': 85.043, 'eval_steps_per_second': 5.318, 'epoch': 1.3045464433326082}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to swag_lora_ft/checkpoint-1500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google-bert--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "tokenizer config file saved in swag_lora_ft/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in swag_lora_ft/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [swag_lora_ft/checkpoint-500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step 1550] {'loss': 0.9047, 'grad_norm': 1.8018749952316284, 'learning_rate': 2.4489533011272145e-05, 'epoch': 1.3480530780944093}\n",
      "[step 1600] {'loss': 0.8971, 'grad_norm': 2.3629279136657715, 'learning_rate': 2.384541062801933e-05, 'epoch': 1.3915597128562105}\n",
      "[step 1650] {'loss': 0.8899, 'grad_norm': 1.8971103429794312, 'learning_rate': 2.3201288244766506e-05, 'epoch': 1.4350663476180117}\n",
      "[step 1700] {'loss': 0.8892, 'grad_norm': 1.869386911392212, 'learning_rate': 2.255716586151369e-05, 'epoch': 1.4785729823798128}\n",
      "[step 1750] {'loss': 0.89, 'grad_norm': 2.1292409896850586, 'learning_rate': 2.191304347826087e-05, 'epoch': 1.522079617141614}\n",
      "[step 1800] {'loss': 0.874, 'grad_norm': 1.844489574432373, 'learning_rate': 2.1268921095008053e-05, 'epoch': 1.5655862519034152}\n",
      "[step 1850] {'loss': 0.8993, 'grad_norm': 1.6428722143173218, 'learning_rate': 2.0624798711755237e-05, 'epoch': 1.6090928866652163}\n",
      "[step 1900] {'loss': 0.8793, 'grad_norm': 1.7100204229354858, 'learning_rate': 1.9980676328502417e-05, 'epoch': 1.6525995214270175}\n",
      "[step 1950] {'loss': 0.8648, 'grad_norm': 2.2269821166992188, 'learning_rate': 1.9336553945249598e-05, 'epoch': 1.6961061561888187}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20006\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step 2000] {'loss': 0.8959, 'grad_norm': 1.643061637878418, 'learning_rate': 1.869243156199678e-05, 'epoch': 1.7396127909506198}\n",
      "[step 2000] {'eval_loss': 0.7216517925262451, 'eval_accuracy': 0.7180845746276118, 'eval_runtime': 232.7805, 'eval_samples_per_second': 85.944, 'eval_steps_per_second': 5.374, 'epoch': 1.7396127909506198}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to swag_lora_ft/checkpoint-2000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google-bert--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "tokenizer config file saved in swag_lora_ft/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in swag_lora_ft/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [swag_lora_ft/checkpoint-1000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step 2050] {'loss': 0.8633, 'grad_norm': 2.08097505569458, 'learning_rate': 1.8048309178743965e-05, 'epoch': 1.783119425712421}\n",
      "[step 2100] {'loss': 0.8867, 'grad_norm': 2.101127862930298, 'learning_rate': 1.7404186795491145e-05, 'epoch': 1.8266260604742222}\n",
      "[step 2150] {'loss': 0.8683, 'grad_norm': 2.365368366241455, 'learning_rate': 1.6760064412238325e-05, 'epoch': 1.8701326952360235}\n",
      "[step 2200] {'loss': 0.8654, 'grad_norm': 2.004598379135132, 'learning_rate': 1.611594202898551e-05, 'epoch': 1.9136393299978247}\n",
      "[step 2250] {'loss': 0.8663, 'grad_norm': 2.1815133094787598, 'learning_rate': 1.547181964573269e-05, 'epoch': 1.9571459647596259}\n",
      "[step 2300] {'loss': 0.8613, 'grad_norm': 1.0227664709091187, 'learning_rate': 1.4827697262479873e-05, 'epoch': 2.0}\n",
      "[step 2350] {'loss': 0.8904, 'grad_norm': 1.8342633247375488, 'learning_rate': 1.4183574879227053e-05, 'epoch': 2.043506634761801}\n",
      "[step 2400] {'loss': 0.8689, 'grad_norm': 2.040992259979248, 'learning_rate': 1.3539452495974237e-05, 'epoch': 2.0870132695236023}\n",
      "[step 2450] {'loss': 0.8651, 'grad_norm': 1.8584790229797363, 'learning_rate': 1.2895330112721419e-05, 'epoch': 2.1305199042854035}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20006\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step 2500] {'loss': 0.8769, 'grad_norm': 1.8550193309783936, 'learning_rate': 1.2251207729468599e-05, 'epoch': 2.1740265390472047}\n",
      "[step 2500] {'eval_loss': 0.7085609436035156, 'eval_accuracy': 0.7251324602619215, 'eval_runtime': 233.5335, 'eval_samples_per_second': 85.667, 'eval_steps_per_second': 5.357, 'epoch': 2.1740265390472047}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to swag_lora_ft/checkpoint-2500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google-bert--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "tokenizer config file saved in swag_lora_ft/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in swag_lora_ft/checkpoint-2500/special_tokens_map.json\n",
      "Deleting older checkpoint [swag_lora_ft/checkpoint-1500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step 2550] {'loss': 0.8712, 'grad_norm': 1.9808539152145386, 'learning_rate': 1.1607085346215783e-05, 'epoch': 2.217533173809006}\n",
      "[step 2600] {'loss': 0.889, 'grad_norm': 1.9283663034439087, 'learning_rate': 1.0962962962962965e-05, 'epoch': 2.261039808570807}\n",
      "[step 2650] {'loss': 0.8714, 'grad_norm': 2.362959861755371, 'learning_rate': 1.0318840579710145e-05, 'epoch': 2.304546443332608}\n",
      "[step 2700] {'loss': 0.8548, 'grad_norm': 2.3126933574676514, 'learning_rate': 9.674718196457329e-06, 'epoch': 2.3480530780944093}\n",
      "[step 2750] {'loss': 0.8488, 'grad_norm': 2.0544803142547607, 'learning_rate': 9.030595813204509e-06, 'epoch': 2.3915597128562105}\n",
      "[step 2800] {'loss': 0.8783, 'grad_norm': 1.9095851182937622, 'learning_rate': 8.38647342995169e-06, 'epoch': 2.4350663476180117}\n",
      "[step 2850] {'loss': 0.8587, 'grad_norm': 1.913783073425293, 'learning_rate': 7.742351046698874e-06, 'epoch': 2.478572982379813}\n",
      "[step 2900] {'loss': 0.8628, 'grad_norm': 2.070373773574829, 'learning_rate': 7.098228663446055e-06, 'epoch': 2.522079617141614}\n",
      "[step 2950] {'loss': 0.865, 'grad_norm': 2.079653024673462, 'learning_rate': 6.4541062801932375e-06, 'epoch': 2.565586251903415}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20006\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step 3000] {'loss': 0.8552, 'grad_norm': 2.638636827468872, 'learning_rate': 5.809983896940419e-06, 'epoch': 2.6090928866652163}\n",
      "[step 3000] {'eval_loss': 0.7016574740409851, 'eval_accuracy': 0.7278816355093471, 'eval_runtime': 234.7272, 'eval_samples_per_second': 85.231, 'eval_steps_per_second': 5.33, 'epoch': 2.6090928866652163}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to swag_lora_ft/checkpoint-3000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google-bert--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "tokenizer config file saved in swag_lora_ft/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in swag_lora_ft/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [swag_lora_ft/checkpoint-2000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step 3050] {'loss': 0.8605, 'grad_norm': 1.938331127166748, 'learning_rate': 5.1658615136876014e-06, 'epoch': 2.6525995214270175}\n",
      "[step 3100] {'loss': 0.8724, 'grad_norm': 2.0513417720794678, 'learning_rate': 4.5217391304347826e-06, 'epoch': 2.6961061561888187}\n",
      "[step 3150] {'loss': 0.8404, 'grad_norm': 1.9035868644714355, 'learning_rate': 3.8776167471819645e-06, 'epoch': 2.73961279095062}\n",
      "[step 3200] {'loss': 0.8731, 'grad_norm': 1.8559490442276, 'learning_rate': 3.2334943639291465e-06, 'epoch': 2.783119425712421}\n",
      "[step 3250] {'loss': 0.8707, 'grad_norm': 1.7530736923217773, 'learning_rate': 2.5893719806763284e-06, 'epoch': 2.826626060474222}\n",
      "[step 3300] {'loss': 0.8832, 'grad_norm': 1.9505352973937988, 'learning_rate': 1.9452495974235104e-06, 'epoch': 2.8701326952360233}\n",
      "[step 3350] {'loss': 0.8555, 'grad_norm': 2.5170297622680664, 'learning_rate': 1.3011272141706926e-06, 'epoch': 2.9136393299978245}\n",
      "[step 3400] {'loss': 0.8712, 'grad_norm': 2.0748751163482666, 'learning_rate': 6.570048309178745e-07, 'epoch': 2.9571459647596257}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to swag_lora_ft/checkpoint-3450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step 3450] {'loss': 0.8654, 'grad_norm': 2.018608808517456, 'learning_rate': 1.2882447665056362e-08, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google-bert--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "tokenizer config file saved in swag_lora_ft/checkpoint-3450/tokenizer_config.json\n",
      "Special tokens file saved in swag_lora_ft/checkpoint-3450/special_tokens_map.json\n",
      "Deleting older checkpoint [swag_lora_ft/checkpoint-2500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from swag_lora_ft/checkpoint-3000 (score: 0.7278816355093471).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step 3450] {'train_runtime': 8818.7515, 'train_samples_per_second': 25.019, 'train_steps_per_second': 0.391, 'total_flos': 5.606065317204336e+16, 'train_loss': 0.9414606807542883, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3450, training_loss=0.9414606807542883, metrics={'train_runtime': 8818.7515, 'train_samples_per_second': 25.019, 'train_steps_per_second': 0.391, 'total_flos': 5.606065317204336e+16, 'train_loss': 0.9414606807542883, 'epoch': 3.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune visible progress (Transformers 4.47 compatible)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from evaluate import load\n",
    "from transformers import (\n",
    "    TrainingArguments, Trainer,\n",
    "    IntervalStrategy, SchedulerType,\n",
    "    TrainerCallback,\n",
    ")\n",
    "from transformers.utils import logging as hf_logging\n",
    "\n",
    "# Make logs visible in the cell; silence wandb noise\n",
    "hf_logging.set_verbosity_info()\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"   # or: os.environ[\"WANDB_MODE\"] = \"offline\"\n",
    "\n",
    "# Metrics\n",
    "accuracy_metric = load(\"accuracy\")\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds  = np.argmax(pred.predictions, axis=1)\n",
    "    return accuracy_metric.compute(predictions=preds, references=labels)\n",
    "\n",
    "# Training arguments (step-level eval/save + frequent logging)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"swag_lora_ft\",\n",
    "\n",
    "    do_eval=True,\n",
    "    eval_strategy=IntervalStrategy.STEPS,   # 4.47 naming\n",
    "    eval_steps=500,\n",
    "    save_strategy=IntervalStrategy.STEPS,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "\n",
    "    learning_rate=4e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=SchedulerType.LINEAR,\n",
    "\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=2,\n",
    "\n",
    "    # visible logs / progress\n",
    "    logging_strategy=IntervalStrategy.STEPS,\n",
    "    logging_steps=50,         # print every 50 steps\n",
    "    disable_tqdm=False,       # show progress bar\n",
    "    report_to=\"none\",         # no wandb/tensorboard\n",
    "\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")\n",
    "\n",
    "# Tiny callback to guarantee prints even if buffering happens\n",
    "class PrintCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs:\n",
    "            print(f\"[step {state.global_step}] {logs}\")\n",
    "\n",
    "# Trainer (reuses your existing objects: model_with_lora, train_ds, eval_ds, data_collator, tokenizer)\n",
    "trainer = Trainer(\n",
    "    model=model_with_lora,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,          # ok; may show a future deprecation warning\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[PrintCallback()],\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T13:43:14.670460Z",
     "iopub.status.busy": "2025-08-24T13:43:14.670212Z",
     "iopub.status.idle": "2025-08-24T13:51:03.627617Z",
     "shell.execute_reply": "2025-08-24T13:51:03.627024Z",
     "shell.execute_reply.started": "2025-08-24T13:43:14.670434Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20006\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 20006\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step 3450] {'eval_loss': 0.7016574740409851, 'eval_accuracy': 0.7278816355093471, 'eval_runtime': 234.5594, 'eval_samples_per_second': 85.292, 'eval_steps_per_second': 5.333, 'epoch': 3.0}\n",
      "‚Üí Validation Accuracy:  72.79%\n",
      "‚Üí Validation Perplexity: 2.02\n",
      "‚Üí Confusion Matrix:\n",
      " [[3616  421  453  443]\n",
      " [ 455 3658  456  460]\n",
      " [ 421  483 3659  475]\n",
      " [ 436  447  494 3629]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate & report\n",
    "metrics = trainer.evaluate()\n",
    "\n",
    "# Perplexity & confusion matrix\n",
    "perplexity = np.exp(metrics[\"eval_loss\"])\n",
    "print(f\"‚Üí Validation Accuracy:  {100*(metrics['eval_accuracy']):.2f}%\")\n",
    "print(f\"‚Üí Validation Perplexity: {perplexity:.2f}\")\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "preds_output = trainer.predict(eval_ds)\n",
    "preds = np.argmax(preds_output.predictions, axis=1)\n",
    "cm = confusion_matrix(preds_output.label_ids, preds)\n",
    "print(\"‚Üí Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T13:51:03.628490Z",
     "iopub.status.busy": "2025-08-24T13:51:03.628300Z",
     "iopub.status.idle": "2025-08-24T13:51:03.634929Z",
     "shell.execute_reply": "2025-08-24T13:51:03.634184Z",
     "shell.execute_reply.started": "2025-08-24T13:51:03.628474Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Method   Accuracy\n",
      "0        Baseline (No ICL)  39.163251\n",
      "1  Few shot learning (ICL)  37.663701\n",
      "2   Chain of Thought (ICL)  40.077977\n",
      "3   Fine-Tuned BERT + LoRA  72.788164\n"
     ]
    }
   ],
   "source": [
    "ft_accuracy = 100*(metrics[\"eval_accuracy\"])\n",
    "icl_results.append((\"Fine-Tuned BERT + LoRA\", ft_accuracy))\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(icl_results, columns=[\"Method\", \"Accuracy\"])\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. In-Context Learning with the Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T13:51:03.636349Z",
     "iopub.status.busy": "2025-08-24T13:51:03.636091Z",
     "iopub.status.idle": "2025-08-24T13:51:03.651237Z",
     "shell.execute_reply": "2025-08-24T13:51:03.650639Z",
     "shell.execute_reply.started": "2025-08-24T13:51:03.636329Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import math\n",
    "\n",
    "# make sure model is on device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_with_lora.to(device)\n",
    "\n",
    "\n",
    "def evaluate_loader(model, loader, description):\n",
    "    model.eval()            # set eval mode\n",
    "    all_preds, all_labels = [], []\n",
    "    total_loss, total_examples = 0.0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=description):\n",
    "            batch = {k: v.to(device) for k,v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss.item()\n",
    "            bs = batch[\"labels\"].size(0)\n",
    "            total_loss    += loss * bs\n",
    "            total_examples+= bs\n",
    "\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(batch[\"labels\"].cpu().tolist())\n",
    "\n",
    "    avg_loss   = total_loss / total_examples\n",
    "    perplexity = math.exp(avg_loss)\n",
    "    acc        = sum(p==l for p,l in zip(all_preds, all_labels)) / len(all_labels)\n",
    "\n",
    "    print(f\"\\nüìä {description} Accuracy:    {100*(acc):.4f}%\")\n",
    "    print(f\"üìä {description} Perplexity: {perplexity:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    print(f\"\\n{description} Confusion Matrix:\\n{cm}\\n\")\n",
    "\n",
    "    cr = classification_report(all_labels, all_preds, digits=4)\n",
    "    print(f\"{description} Classification Report:\\n{cr}\\n\")\n",
    "\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-shot ICL with fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T13:51:03.652167Z",
     "iopub.status.busy": "2025-08-24T13:51:03.651877Z",
     "iopub.status.idle": "2025-08-24T14:11:39.511442Z",
     "shell.execute_reply": "2025-08-24T14:11:39.510605Z",
     "shell.execute_reply.started": "2025-08-24T13:51:03.652143Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuned Few-Shot ICL: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2501/2501 [20:35<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Fine-Tuned Few-Shot ICL Accuracy:    58.1326%\n",
      "üìä Fine-Tuned Few-Shot ICL Perplexity: 2.7297\n",
      "\n",
      "Fine-Tuned Few-Shot ICL Confusion Matrix:\n",
      "[[2839  756  648  690]\n",
      " [ 673 3051  670  635]\n",
      " [ 693  800 2834  711]\n",
      " [ 665  738  697 2906]]\n",
      "\n",
      "Fine-Tuned Few-Shot ICL Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5830    0.5755    0.5792      4933\n",
      "           1     0.5708    0.6067    0.5882      5029\n",
      "           2     0.5845    0.5625    0.5733      5038\n",
      "           3     0.5880    0.5805    0.5842      5006\n",
      "\n",
      "    accuracy                         0.5813     20006\n",
      "   macro avg     0.5816    0.5813    0.5812     20006\n",
      "weighted avg     0.5815    0.5813    0.5812     20006\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fs_acc = evaluate_loader(model_with_lora, fewshot_icl_loader, \"Fine-Tuned Few-Shot ICL\")\n",
    "icl_results.append((\"Fine-Tuned Few-Shot ICL\", 100*fs_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain of thought ICL with fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T14:11:39.512324Z",
     "iopub.status.busy": "2025-08-24T14:11:39.512133Z",
     "iopub.status.idle": "2025-08-24T14:16:03.837959Z",
     "shell.execute_reply": "2025-08-24T14:16:03.837175Z",
     "shell.execute_reply.started": "2025-08-24T14:11:39.512308Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuned CoT ICL: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2501/2501 [04:24<00:00,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Fine-Tuned CoT ICL Accuracy:    69.1742%\n",
      "üìä Fine-Tuned CoT ICL Perplexity: 2.1903\n",
      "\n",
      "Fine-Tuned CoT ICL Confusion Matrix:\n",
      "[[3217  658  572  486]\n",
      " [ 397 3701  482  449]\n",
      " [ 411  636 3492  499]\n",
      " [ 393  627  557 3429]]\n",
      "\n",
      "Fine-Tuned CoT ICL Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7282    0.6521    0.6881      4933\n",
      "           1     0.6583    0.7359    0.6950      5029\n",
      "           2     0.6843    0.6931    0.6887      5038\n",
      "           3     0.7051    0.6850    0.6949      5006\n",
      "\n",
      "    accuracy                         0.6917     20006\n",
      "   macro avg     0.6940    0.6915    0.6917     20006\n",
      "weighted avg     0.6938    0.6917    0.6917     20006\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cot_acc = evaluate_loader(model_with_lora, cot_loader, \"Fine-Tuned CoT ICL\")\n",
    "icl_results.append((\"Fine-Tuned CoT ICL\", 100*cot_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T14:16:03.839776Z",
     "iopub.status.busy": "2025-08-24T14:16:03.838899Z",
     "iopub.status.idle": "2025-08-24T14:16:03.846468Z",
     "shell.execute_reply": "2025-08-24T14:16:03.845547Z",
     "shell.execute_reply.started": "2025-08-24T14:16:03.839742Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Method   Accuracy\n",
      "0        Baseline (No ICL)  39.163251\n",
      "1  Few shot learning (ICL)  37.663701\n",
      "2   Chain of Thought (ICL)  40.077977\n",
      "3   Fine-Tuned BERT + LoRA  72.788164\n",
      "4  Fine-Tuned Few-Shot ICL   0.581326\n",
      "5       Fine-Tuned CoT ICL   0.691742\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "results_df = pd.DataFrame(icl_results, columns=[\"Method\", \"Accuracy\"])\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Analyze the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T14:16:03.847620Z",
     "iopub.status.busy": "2025-08-24T14:16:03.847393Z",
     "iopub.status.idle": "2025-08-24T14:17:05.691215Z",
     "shell.execute_reply": "2025-08-24T14:17:05.690628Z",
     "shell.execute_reply.started": "2025-08-24T14:16:03.847602Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ad0864edde4fcfaf39a899f0b6d977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51099d1d10e04a85a2210a19ead107a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare the test datasets\n",
    "\n",
    "# --- a) Baseline test (no ICL, pretrained BERT) ---\n",
    "test_baseline = tokenized_dataset[\"test\"]\n",
    "test_baseline_loader = DataLoader(test_baseline, batch_size=8, collate_fn=data_collator)\n",
    "\n",
    "# --- b) Few-Shot ICL on test ---\n",
    "test_fewshot = dataset[\"test\"].map(\n",
    "    preprocess_fewshot_icl_batch,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"test\"].column_names\n",
    ")\n",
    "# drop old label column if it exists, keep only MCQ fields\n",
    "if \"label\" in test_fewshot.column_names:\n",
    "    test_fewshot = test_fewshot.remove_columns([\"label\"])\n",
    "keep = [\"input_ids\", \"attention_mask\", \"token_type_ids\", \"labels\"]\n",
    "test_fewshot = test_fewshot.remove_columns([c for c in test_fewshot.column_names if c not in keep])\n",
    "test_fewshot_loader = DataLoader(test_fewshot, batch_size=8, collate_fn=data_collator)\n",
    "\n",
    "# --- c) Chain-of-Thought ICL on test ---\n",
    "test_cot = dataset[\"test\"].map(\n",
    "    preprocess_cot_batch,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"test\"].column_names\n",
    ")\n",
    "if \"label\" in test_cot.column_names:\n",
    "    test_cot = test_cot.remove_columns([\"label\"])\n",
    "test_cot = test_cot.remove_columns([c for c in test_cot.column_names if c not in keep])\n",
    "test_cot_loader = DataLoader(test_cot, batch_size=8, collate_fn=data_collator)\n",
    "\n",
    "\n",
    "test_results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T15:34:38.724561Z",
     "iopub.status.busy": "2025-08-24T15:34:38.724275Z",
     "iopub.status.idle": "2025-08-24T15:34:38.732547Z",
     "shell.execute_reply": "2025-08-24T15:34:38.731876Z",
     "shell.execute_reply.started": "2025-08-24T15:34:38.724541Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_loader_test(model, loader, description):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a given DataLoader, handling both:\n",
    "    - Baseline datasets with list-of-lists labels (from preprocess_swag)\n",
    "    - Few-shot / CoT datasets with flat integer labels\n",
    "    Computes accuracy, perplexity, confusion matrix, and classification report.\n",
    "    \"\"\"\n",
    "    model.eval()  # set evaluation mode\n",
    "    all_preds, all_labels = [], []\n",
    "    total_loss, total_examples = 0.0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=description):\n",
    "            # --- Flatten labels for baseline if necessary ---\n",
    "            labels_raw = batch[\"labels\"]\n",
    "            \n",
    "            if isinstance(labels_raw[0], (list, tuple)):\n",
    "                # Flatten: take the first element of each list (baseline dataset)\n",
    "                batch_labels = torch.tensor([l[0] for l in labels_raw], device=device)\n",
    "            else:\n",
    "                # Already flat (ICL datasets)\n",
    "                batch_labels = labels_raw.to(device)\n",
    "\n",
    "            # Move all other tensors to device\n",
    "            batch_tensors = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n",
    "            batch_tensors[\"labels\"] = batch_labels\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(**batch_tensors)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = outputs.loss.item()\n",
    "            bs = batch_labels.size(0)\n",
    "            total_loss += loss * bs\n",
    "            total_examples += bs\n",
    "\n",
    "            # Predictions\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(batch_labels.cpu().tolist())\n",
    "\n",
    "    # Metrics\n",
    "    avg_loss = total_loss / total_examples\n",
    "    perplexity = math.exp(avg_loss)\n",
    "    acc = sum(p == l for p, l in zip(all_preds, all_labels)) / len(all_labels)\n",
    "\n",
    "    print(f\"\\nüìä {description} Accuracy: {100*acc:.4f}%\")\n",
    "    print(f\"üìä {description} Perplexity: {perplexity:.4f}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    print(f\"\\n{description} Confusion Matrix:\\n{cm}\\n\")\n",
    "\n",
    "    # Classification Report\n",
    "    cr = classification_report(all_labels, all_preds, digits=4)\n",
    "    print(f\"{description} Classification Report:\\n{cr}\\n\")\n",
    "\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T15:34:42.503479Z",
     "iopub.status.busy": "2025-08-24T15:34:42.503240Z",
     "iopub.status.idle": "2025-08-24T15:34:42.545588Z",
     "shell.execute_reply": "2025-08-24T15:34:42.544703Z",
     "shell.execute_reply.started": "2025-08-24T15:34:42.503464Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Baseline:   0%|          | 0/2501 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_180/3373941391.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# a) Baseline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbaseline_test_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_loader_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_baseline_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Test Baseline\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Baseline (No ICL)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_test_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_180/157243941.py\u001b[0m in \u001b[0;36mevaluate_loader_test\u001b[0;34m(model, loader, description)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;31m# Already flat (ICL datasets)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# Move all other tensors to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# a) Baseline\n",
    "baseline_test_acc = evaluate_loader_test(base_model, test_baseline_loader, \"Test Baseline\")\n",
    "test_results.append((\"Baseline (No ICL)\", baseline_test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-24T14:17:06.091981Z",
     "iopub.status.idle": "2025-08-24T14:17:06.092252Z",
     "shell.execute_reply": "2025-08-24T14:17:06.092147Z",
     "shell.execute_reply.started": "2025-08-24T14:17:06.092131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# b) Few‚ÄêShot ICL (pre-fine-tune)\n",
    "fs_test_acc = evaluate_loader(base_model, test_fewshot_loader, \"Test Few-Shot ICL\")\n",
    "test_results.append((\"Few-Shot ICL (pre-FT)\", fs_test_acc))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-24T14:17:06.093490Z",
     "iopub.status.idle": "2025-08-24T14:17:06.093716Z",
     "shell.execute_reply": "2025-08-24T14:17:06.093611Z",
     "shell.execute_reply.started": "2025-08-24T14:17:06.093602Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# c) CoT ICL (pre-fine-tune)\n",
    "cot_test_acc = evaluate_loader(base_model, test_cot_loader, \"Test CoT ICL\")\n",
    "test_results.append((\"CoT ICL (pre-FT)\", cot_test_acc))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-24T14:17:06.094818Z",
     "iopub.status.idle": "2025-08-24T14:17:06.095146Z",
     "shell.execute_reply": "2025-08-24T14:17:06.094983Z",
     "shell.execute_reply.started": "2025-08-24T14:17:06.094969Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# d) Fine-tuned BERT + LoRA (no ICL)\n",
    "ft_test_acc = evaluate_loader(model_with_lora, test_baseline_loader, \"Test Fine-Tuned BERT+LoRA\")\n",
    "test_results.append((\"Fine-Tuned BERT+LoRA\", ft_test_acc))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-24T14:17:06.096260Z",
     "iopub.status.idle": "2025-08-24T14:17:06.096536Z",
     "shell.execute_reply": "2025-08-24T14:17:06.096430Z",
     "shell.execute_reply.started": "2025-08-24T14:17:06.096417Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# e) Few-Shot ICL on fine-tuned model\n",
    "fs_ft_test_acc = evaluate_loader(model_with_lora, test_fewshot_loader, \"Test Fine-Tuned Few-Shot ICL\")\n",
    "test_results.append((\"Few-Shot ICL (FT)\", fs_ft_test_acc))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-24T14:17:06.097583Z",
     "iopub.status.idle": "2025-08-24T14:17:06.097882Z",
     "shell.execute_reply": "2025-08-24T14:17:06.097743Z",
     "shell.execute_reply.started": "2025-08-24T14:17:06.097729Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# f) CoT ICL on fine-tuned model\n",
    "cot_ft_test_acc = evaluate_loader(model_with_lora, test_cot_loader, \"Test Fine-Tuned CoT ICL\")\n",
    "test_results.append((\"CoT ICL (FT)\", cot_ft_test_acc))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Report All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-24T14:17:06.099040Z",
     "iopub.status.idle": "2025-08-24T14:17:06.099359Z",
     "shell.execute_reply": "2025-08-24T14:17:06.099218Z",
     "shell.execute_reply.started": "2025-08-24T14:17:06.099203Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(test_results, columns=[\"Method\", \"Test Accuracy\"])\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
